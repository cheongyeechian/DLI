{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheongyeechian/DLI/blob/main/Lim_Li_Vorn_TP073982.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers accelerate scikit-learn matplotlib\n",
        "\n",
        "import os, re, time, random, gc, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertTokenizer, BertConfig, BertModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,\n",
        "                             roc_curve)"
      ],
      "metadata": {
        "id": "1a3E4cX-jwAj"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# [0] Colab: mount Google Drive\n",
        "# ------------------------------------------------------------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PtIG8M-kH9D",
        "outputId": "10695e9a-4b4c-4364-cd8a-ddcda5959730"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# [1] CONFIG â€” set your paths\n",
        "#    Put these three files in Drive and update the paths below.\n",
        "# ------------------------------------------------------------\n",
        "CSV_PATH     = \"/content/drive/My Drive/DLI Assignment/group_dataset.csv\"  # your dataset\n",
        "VOCAB_TXT    = \"/content/drive/My Drive/DLI Assignment/vocab.txt\"          # your tokenizer vocab\n",
        "URLBERT_PT   = \"/content/drive/My Drive/DLI Assignment/urlBERT.pt\"         # your encoder weights\n",
        "\n",
        "# Training & model hyperparams\n",
        "SEED         = 2025\n",
        "MAX_LEN      = 128\n",
        "BATCH_SIZE   = 64\n",
        "EPOCHS       = 3\n",
        "LR           = 2e-5\n",
        "WARMUP_RATIO = 0.1\n",
        "WEIGHT_DECAY = 0.01\n",
        "DROPOUT      = 0.2\n",
        "KERNEL_SIZES = (2,3,4)\n",
        "NUM_FILTERS  = 128\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pBbuhQKkMzg",
        "outputId": "e4e9e3f9-7017-4b9c-fd7e-6a21f4d1a5b0"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# [2] Reproducibility\n",
        "# ------------------------------------------------------------\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": "G8IfK3HGkevv"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# [4] Tokenizer: use YOUR vocab.txt\n",
        "# ------------------------------------------------------------\n",
        "assert os.path.exists(VOCAB_TXT), f\"vocab.txt not found at {VOCAB_TXT}\"\n",
        "tokenizer = BertTokenizer(vocab_file=VOCAB_TXT, do_lower_case=True, tokenize_chinese_chars=False, strip_accents=False)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print(\"Vocab size:\", VOCAB_SIZE)\n",
        "\n",
        "class UrlDataset(Dataset):\n",
        "    def __init__(self, txts, labels=None, max_len=MAX_LEN):\n",
        "        self.txts = list(txts)\n",
        "        self.labels = None if labels is None else list(labels)\n",
        "        self.max_len = max_len\n",
        "    def __len__(self): return len(self.txts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = tokenizer(\n",
        "            self.txts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
        "        if self.labels is not None:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "train_ds = UrlDataset(X_train, y_train)\n",
        "test_ds  = UrlDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThcaKounki1D",
        "outputId": "65a9162c-3d39-4672-94f7-2c0f78e8ae2e"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RVC5_yVPkqq-"
      }
    }
  ]
}