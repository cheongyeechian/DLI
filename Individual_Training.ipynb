{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheongyeechian/DLI/blob/main/Individual_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52e876b6",
        "outputId": "9c88a7ff-6828-4c1d-8d45-8eb7320ed30c"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Ensure the dataset is downloaded if not already present\n",
        "if not os.path.exists(\"dataset_phishing.csv\"):\n",
        "    try:\n",
        "        # Download the file from Google Drive\n",
        "        !gdown --id 1QrsbselQT_UPK81Pur_rigCKyZKpE9Zq -O dataset_phishing.csv\n",
        "        print(\"Dataset downloaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        # Exit if download fails\n",
        "        exit()\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset_phishing.csv\")\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(\"\\nFirst 5 rows of the dataset:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nShape of the dataset (rows, columns):\")\n",
        "    print(df.shape)\n",
        "    print(\"\\nInformation about the dataset (data types, non-null counts):\")\n",
        "    df.info()\n",
        "    print(\"\\nDistribution of the target variable (status):\")\n",
        "    print(df['status'].value_counts())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'dataset_phishing.csv' not found after download attempt.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during data loading: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "print(\"\\n--- Data Cleaning and Preprocessing ---\")\n",
        "\n",
        "# Drop the 'url' column as it's not needed for the model\n",
        "if 'url' in df.columns:\n",
        "    df = df.drop(\"url\", axis=1)\n",
        "    print(\"'url' column dropped.\")\n",
        "else:\n",
        "    print(\"'url' column not found.\")\n",
        "\n",
        "# Encode the 'status' column using LabelEncoder\n",
        "if 'status' in df.columns:\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"status_encoding\"] = label_encoder.fit_transform(df[\"status\"])\n",
        "    status_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "    print(f\"Status column encoded. Mapping: {status_mapping}\")\n",
        "    # Drop the original 'status' column\n",
        "    df = df.drop(\"status\", axis=1)\n",
        "    print(\"Original 'status' column dropped.\")\n",
        "else:\n",
        "    print(\"'status' column not found or already processed.\")\n",
        "\n",
        "\n",
        "# Handle -1 values in 'domain_age' and 'domain_registration_length'\n",
        "print(\"\\nHandling -1 values in 'domain_age' and 'domain_registration_length'...\")\n",
        "\n",
        "# Calculate the mean of the relevant columns excluding -1\n",
        "mean_domain_age = df[df['domain_age'] != -1]['domain_age'].mean()\n",
        "mean_domain_registration_length = df[df['domain_registration_length'] != -1]['domain_registration_length'].mean()\n",
        "\n",
        "# Replace -1 values with the calculated means\n",
        "df['domain_age'] = df['domain_age'].replace(-1, mean_domain_age)\n",
        "df['domain_registration_length'] = df['domain_registration_length'].replace(-1, mean_domain_registration_length)\n",
        "\n",
        "print(f\"Replaced -1 in 'domain_age' with mean: {mean_domain_age:.2f}\")\n",
        "print(f\"Replaced -1 in 'domain_registration_length' with mean: {mean_domain_registration_length:.2f}\")\n",
        "\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('status_encoding', axis=1)\n",
        "y = df['status_encoding']\n",
        "\n",
        "print(f\"\\nFeatures (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTraining set features (X_train) shape: {X_train.shape}\")\n",
        "print(f\"Testing set features (X_test) shape: {X_test.shape}\")\n",
        "print(f\"Training set target (y_train) shape: {y_train.shape}\")\n",
        "print(f\"Testing set target (y_test) shape: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nPreprocessing complete. Data is ready for model training.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "                                                 url  length_url  \\\n",
            "0              http://www.crestonwood.com/router.php          37   \n",
            "1  http://shadetreetechnology.com/V4/validation/a...          77   \n",
            "2  https://support-appleld.com.secureupdate.duila...         126   \n",
            "3                                 http://rgipt.ac.in          18   \n",
            "4  http://www.iracing.com/tracks/gateway-motorspo...          55   \n",
            "\n",
            "   length_hostname  ip  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  nb_or  ...  \\\n",
            "0               19   0        3           0      0      0       0      0  ...   \n",
            "1               23   1        1           0      0      0       0      0  ...   \n",
            "2               50   1        4           1      0      1       2      0  ...   \n",
            "3               11   0        2           0      0      0       0      0  ...   \n",
            "4               15   0        2           2      0      0       0      0  ...   \n",
            "\n",
            "   domain_in_title  domain_with_copyright  whois_registered_domain  \\\n",
            "0                0                      1                        0   \n",
            "1                1                      0                        0   \n",
            "2                1                      0                        0   \n",
            "3                1                      0                        0   \n",
            "4                0                      1                        0   \n",
            "\n",
            "   domain_registration_length  domain_age  web_traffic  dns_record  \\\n",
            "0                          45          -1            0           1   \n",
            "1                          77        5767            0           0   \n",
            "2                          14        4004      5828815           0   \n",
            "3                          62          -1       107721           0   \n",
            "4                         224        8175         8725           0   \n",
            "\n",
            "   google_index  page_rank      status  \n",
            "0             1          4  legitimate  \n",
            "1             1          2    phishing  \n",
            "2             1          0    phishing  \n",
            "3             0          3  legitimate  \n",
            "4             0          6  legitimate  \n",
            "\n",
            "[5 rows x 89 columns]\n",
            "\n",
            "Shape of the dataset (rows, columns):\n",
            "(11430, 89)\n",
            "\n",
            "Information about the dataset (data types, non-null counts):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11430 entries, 0 to 11429\n",
            "Data columns (total 89 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   url                         11430 non-null  object \n",
            " 1   length_url                  11430 non-null  int64  \n",
            " 2   length_hostname             11430 non-null  int64  \n",
            " 3   ip                          11430 non-null  int64  \n",
            " 4   nb_dots                     11430 non-null  int64  \n",
            " 5   nb_hyphens                  11430 non-null  int64  \n",
            " 6   nb_at                       11430 non-null  int64  \n",
            " 7   nb_qm                       11430 non-null  int64  \n",
            " 8   nb_and                      11430 non-null  int64  \n",
            " 9   nb_or                       11430 non-null  int64  \n",
            " 10  nb_eq                       11430 non-null  int64  \n",
            " 11  nb_underscore               11430 non-null  int64  \n",
            " 12  nb_tilde                    11430 non-null  int64  \n",
            " 13  nb_percent                  11430 non-null  int64  \n",
            " 14  nb_slash                    11430 non-null  int64  \n",
            " 15  nb_star                     11430 non-null  int64  \n",
            " 16  nb_colon                    11430 non-null  int64  \n",
            " 17  nb_comma                    11430 non-null  int64  \n",
            " 18  nb_semicolumn               11430 non-null  int64  \n",
            " 19  nb_dollar                   11430 non-null  int64  \n",
            " 20  nb_space                    11430 non-null  int64  \n",
            " 21  nb_www                      11430 non-null  int64  \n",
            " 22  nb_com                      11430 non-null  int64  \n",
            " 23  nb_dslash                   11430 non-null  int64  \n",
            " 24  http_in_path                11430 non-null  int64  \n",
            " 25  https_token                 11430 non-null  int64  \n",
            " 26  ratio_digits_url            11430 non-null  float64\n",
            " 27  ratio_digits_host           11430 non-null  float64\n",
            " 28  punycode                    11430 non-null  int64  \n",
            " 29  port                        11430 non-null  int64  \n",
            " 30  tld_in_path                 11430 non-null  int64  \n",
            " 31  tld_in_subdomain            11430 non-null  int64  \n",
            " 32  abnormal_subdomain          11430 non-null  int64  \n",
            " 33  nb_subdomains               11430 non-null  int64  \n",
            " 34  prefix_suffix               11430 non-null  int64  \n",
            " 35  random_domain               11430 non-null  int64  \n",
            " 36  shortening_service          11430 non-null  int64  \n",
            " 37  path_extension              11430 non-null  int64  \n",
            " 38  nb_redirection              11430 non-null  int64  \n",
            " 39  nb_external_redirection     11430 non-null  int64  \n",
            " 40  length_words_raw            11430 non-null  int64  \n",
            " 41  char_repeat                 11430 non-null  int64  \n",
            " 42  shortest_words_raw          11430 non-null  int64  \n",
            " 43  shortest_word_host          11430 non-null  int64  \n",
            " 44  shortest_word_path          11430 non-null  int64  \n",
            " 45  longest_words_raw           11430 non-null  int64  \n",
            " 46  longest_word_host           11430 non-null  int64  \n",
            " 47  longest_word_path           11430 non-null  int64  \n",
            " 48  avg_words_raw               11430 non-null  float64\n",
            " 49  avg_word_host               11430 non-null  float64\n",
            " 50  avg_word_path               11430 non-null  float64\n",
            " 51  phish_hints                 11430 non-null  int64  \n",
            " 52  domain_in_brand             11430 non-null  int64  \n",
            " 53  brand_in_subdomain          11430 non-null  int64  \n",
            " 54  brand_in_path               11430 non-null  int64  \n",
            " 55  suspecious_tld              11430 non-null  int64  \n",
            " 56  statistical_report          11430 non-null  int64  \n",
            " 57  nb_hyperlinks               11430 non-null  int64  \n",
            " 58  ratio_intHyperlinks         11430 non-null  float64\n",
            " 59  ratio_extHyperlinks         11430 non-null  float64\n",
            " 60  ratio_nullHyperlinks        11430 non-null  int64  \n",
            " 61  nb_extCSS                   11430 non-null  int64  \n",
            " 62  ratio_intRedirection        11430 non-null  int64  \n",
            " 63  ratio_extRedirection        11430 non-null  float64\n",
            " 64  ratio_intErrors             11430 non-null  int64  \n",
            " 65  ratio_extErrors             11430 non-null  float64\n",
            " 66  login_form                  11430 non-null  int64  \n",
            " 67  external_favicon            11430 non-null  int64  \n",
            " 68  links_in_tags               11430 non-null  float64\n",
            " 69  submit_email                11430 non-null  int64  \n",
            " 70  ratio_intMedia              11430 non-null  float64\n",
            " 71  ratio_extMedia              11430 non-null  float64\n",
            " 72  sfh                         11430 non-null  int64  \n",
            " 73  iframe                      11430 non-null  int64  \n",
            " 74  popup_window                11430 non-null  int64  \n",
            " 75  safe_anchor                 11430 non-null  float64\n",
            " 76  onmouseover                 11430 non-null  int64  \n",
            " 77  right_clic                  11430 non-null  int64  \n",
            " 78  empty_title                 11430 non-null  int64  \n",
            " 79  domain_in_title             11430 non-null  int64  \n",
            " 80  domain_with_copyright       11430 non-null  int64  \n",
            " 81  whois_registered_domain     11430 non-null  int64  \n",
            " 82  domain_registration_length  11430 non-null  int64  \n",
            " 83  domain_age                  11430 non-null  int64  \n",
            " 84  web_traffic                 11430 non-null  int64  \n",
            " 85  dns_record                  11430 non-null  int64  \n",
            " 86  google_index                11430 non-null  int64  \n",
            " 87  page_rank                   11430 non-null  int64  \n",
            " 88  status                      11430 non-null  object \n",
            "dtypes: float64(13), int64(74), object(2)\n",
            "memory usage: 7.8+ MB\n",
            "\n",
            "Distribution of the target variable (status):\n",
            "status\n",
            "legitimate    5715\n",
            "phishing      5715\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Data Cleaning and Preprocessing ---\n",
            "'url' column dropped.\n",
            "Status column encoded. Mapping: {'legitimate': np.int64(0), 'phishing': np.int64(1)}\n",
            "Original 'status' column dropped.\n",
            "\n",
            "Handling -1 values in 'domain_age' and 'domain_registration_length'...\n",
            "Replaced -1 in 'domain_age' with mean: 4812.59\n",
            "Replaced -1 in 'domain_registration_length' with mean: 494.53\n",
            "\n",
            "Features (X) shape: (11430, 87)\n",
            "Target (y) shape: (11430,)\n",
            "\n",
            "Training set features (X_train) shape: (9144, 87)\n",
            "Testing set features (X_test) shape: (2286, 87)\n",
            "Training set target (y_train) shape: (9144,)\n",
            "Testing set target (y_test) shape: (2286,)\n",
            "\n",
            "Preprocessing complete. Data is ready for model training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1576dcd",
        "outputId": "780961d8-c3e4-4ad7-ad23-c7d398e5b8f0"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import RandomizedSearchCV # Changed from GridSearchCV\n",
        "import numpy as np\n",
        "from scipy.stats import uniform # Needed for RandomizedSearchCV's distribution\n",
        "from scipy.stats import loguniform # Needed for RandomizedSearchCV's distribution\n",
        "\n",
        "print(\"\\n--- Logistic Regression Model Training with Enhancements ---\")\n",
        "\n",
        "# Scale the features\n",
        "scaler_lr = StandardScaler()\n",
        "X_train_scaled_lr = scaler_lr.fit_transform(X_train)\n",
        "X_test_scaled_lr = scaler_lr.transform(X_test)\n",
        "print(\"Features scaled for Logistic Regression.\")\n",
        "\n",
        "# Add polynomial features\n",
        "# Adjust degree based on problem - starting with degree 2\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False) # include_bias=False to avoid adding a column of ones\n",
        "X_train_poly = poly.fit_transform(X_train_scaled_lr)\n",
        "X_test_poly = poly.transform(X_test_scaled_lr)\n",
        "print(f\"Added polynomial features. New training shape: {X_train_poly.shape}\")\n",
        "\n",
        "\n",
        "# Hyperparameter Tuning using RandomizedSearchCV\n",
        "print(\"\\nPerforming RandomizedSearchCV for Hyperparameter Tuning...\")\n",
        "# Optimize the C parameter using RandomizedSearchCV\n",
        "# Using a log-uniform distribution for C is more suitable for scale-invariant search\n",
        "param_dist = {'C': loguniform(1e-3, 1e3)}\n",
        "\n",
        "# Using the data with polynomial features\n",
        "# n_iter controls how many parameter combinations are sampled\n",
        "random_search = RandomizedSearchCV(\n",
        "    LogisticRegression(random_state=42, penalty='l2', solver='lbfgs', max_iter=2000),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of parameter settings that are sampled. Adjust as needed.\n",
        "    cv=3,  # Reduce folds to speed up\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Use all available cores\n",
        ")\n",
        "random_search.fit(X_train_poly, y_train)\n",
        "\n",
        "best_C = random_search.best_params_['C']\n",
        "print(f\"Best C found by RandomizedSearchCV: {best_C}\")\n",
        "\n",
        "# Define the Logistic Regression model with the best C found\n",
        "model_lr = LogisticRegression(random_state=42, C=best_C, penalty='l2', solver='lbfgs', max_iter=2000)\n",
        "\n",
        "# Train the model on the data with polynomial features\n",
        "print(\"\\nTraining Logistic Regression Model with best C and polynomial features...\")\n",
        "model_lr.fit(X_train_poly, y_train)\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Evaluate the model on the test data with polynomial features\n",
        "print(\"Evaluating Logistic Regression Model...\")\n",
        "y_pred_lr = model_lr.predict(X_test_poly)\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr)\n",
        "recall_lr = recall_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"\\nAccuracy (Logistic Regression): {accuracy_lr:.4f}\")\n",
        "print(f\"Precision (Logistic Regression): {precision_lr:.4f}\")\n",
        "print(f\"Recall (Logistic Regression): {recall_lr:.4f}\")\n",
        "print(f\"F1-Score (Logistic Regression): {f1_lr:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix (Logistic Regression):\")\n",
        "print(conf_matrix_lr)\n",
        "\n",
        "print(\"\\n--- Confusion Matrix Breakdown (Logistic Regression) ---\")\n",
        "TN_lr, FP_lr, FN_lr, TP_lr = conf_matrix_lr.ravel()\n",
        "print(f\"True Negatives (Legitimate Correctly Classified): {TN_lr}\")\n",
        "print(f\"False Positives (Legitimate Classified as Phishing): {FP_lr}\")\n",
        "print(f\"False Negatives (Phishing Classified as Legitimate): {FN_lr}\")\n",
        "print(f\"True Positives (Phishing Correctly Classified): {TP_lr}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Logistic Regression Model Training with Enhancements ---\n",
            "Features scaled for Logistic Regression.\n",
            "Added polynomial features. New training shape: (9144, 3915)\n",
            "\n",
            "Performing RandomizedSearchCV for Hyperparameter Tuning...\n"
          ]
        }
      ]
    }
  ]
}